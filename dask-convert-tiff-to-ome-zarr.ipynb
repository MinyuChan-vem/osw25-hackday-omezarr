{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e6b5f6",
   "metadata": {},
   "source": [
    "## Reading the TIFF data\n",
    "\n",
    "In a first step, we read in the TIFF data with `dask-image`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f42eea-0ecb-4b86-bc77-5644501b3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_image.imread import imread\n",
    "from pathlib import Path\n",
    "\n",
    "tiff_image_path = Path(r\"C:\\Users\\kimme\\Documents\\Temp\\osw-data\\Human_neuron.tif\")\n",
    "assert tiff_image_path.exists()\n",
    "tiff_dask = imread(tiff_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2718599",
   "metadata": {},
   "source": [
    "## Exploring the TIFF image\n",
    "\n",
    "In the next section, we can have a look at some of the image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62ba31-f9d3-4753-8661-a15ce6bae926",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tiff_dask))\n",
    "print(tiff_dask.shape)  # ZYX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf547b1-c09e-4260-998c-1d60a21b8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults to each slice being one chunk (i.e. z=1)\n",
    "print(tiff_dask.chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a48a0-ff61-45ad-977d-2c9b3768f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of pulling out one slice (Z=100)\n",
    "tiff_dask[100, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365f598-267c-4ccb-ad29-a2f378bcf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_z_slice(image, z_index):\n",
    "    plt.imshow(image[z_index, :, :], cmap='gray')\n",
    "    plt.title(f'Z slice {z_index}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot a few example z slices\n",
    "plot_z_slice(tiff_dask, 100)\n",
    "plot_z_slice(tiff_dask, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576eb41",
   "metadata": {},
   "source": [
    "## Converting to chunked format (zarr)\n",
    "\n",
    "We have seen that we need to make decisions around storage location, chunk size and compression library and level to write chunked file formats. Let's see whether we can do each of these in Python below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa76f1",
   "metadata": {},
   "source": [
    "Next, we specify the chunk size and the compression in an \"array specification\" (`ArraySpec`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_zarr.v2 import ArraySpec\n",
    "from numcodecs import Zstd\n",
    "from numcodecs import Blosc\n",
    "\n",
    "# As our dask array (and underlying tiff image), has one chunk per z slice. It's most \n",
    "# efficient to keep our ome-zarr chunks with z=1 too.\n",
    "# Chunks of 64x64x64 for example, would require our code to load 64 tiff slices to\n",
    "# write a single chunk. Then load them again for the next and so on...\n",
    "array_spec = ArraySpec(\n",
    "    shape=tiff_dask.shape,\n",
    "    dtype=tiff_dask.dtype,\n",
    "    chunks=(1, tiff_dask.shape[1], tiff_dask.shape[2]),\n",
    "    # compressor=Blosc(cname=\"zstd\", clevel=5),\n",
    ")\n",
    "print(array_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f300a2",
   "metadata": {},
   "source": [
    "Now, we specify where we want to story the chunked file - by default, we'll make a folder next to the tiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67090539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "zarr_path = tiff_image_path.parent / \"chunked_image\"\n",
    "Path.mkdir(zarr_path, exist_ok=True)\n",
    "print(f\"Created a folder at {zarr_path}\")\n",
    "print(f\"Folder contents before creating zarr store {list(zarr_path.iterdir())}\")\n",
    "\n",
    "store = zarr.DirectoryStore(zarr_path)\n",
    "zarr_array = array_spec.to_zarr(store=store, path=\"/\")\n",
    "print(f\"Folder contents after creating zarr store {list(zarr_path.iterdir())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605221",
   "metadata": {},
   "source": [
    "Note that `zarr_array` doesn't contain any pixel data yet (it's full of zeros) - it now just know where and how it should store data.\n",
    "So finally, we need to copy the data to the chunked array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371af991-32f1-4b50-94d0-41ad05f0681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "tiff_dask.to_zarr(zarr_array)\n",
    "end = timer()\n",
    "\n",
    "print(f\"Copying took {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b2014",
   "metadata": {},
   "source": [
    "Let's see what's inside the zarr folder now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Folder contents after copying pixel data into zarr {list(zarr_path.iterdir())}\")\n",
    "print(f\"There are {len(list(zarr_path.iterdir()))-2} data subfolders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748b983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d30e22",
   "metadata": {},
   "source": [
    "Can you explain the number of subfolders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db55306",
   "metadata": {},
   "source": [
    "# Converting to pyramidal file format (OME-zarr)\n",
    "\n",
    "Now we can work on adding lower levels of resolution to the array, and specifying metadata. First, we re-use the same array specification as before, and specity voxel size, units and image name. We also specify that the current array is level 0 of the pyramid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr_models.v04 import Image\n",
    "from ome_zarr_models.v04.axes import Axis\n",
    "\n",
    "voxel_size = 10\n",
    "ome_zarr_image = Image.new(\n",
    "    array_specs = [ArraySpec.from_array(zarr_array)],\n",
    "    paths = [\"level0\"],\n",
    "    axes = [\n",
    "        Axis(name=\"z\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"y\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"x\", type=\"space\", unit=\"um\")\n",
    "    ],\n",
    "    global_scale = [voxel_size, voxel_size, voxel_size],\n",
    "    scales = [[1, 1, 1]],\n",
    "    translations = [[0, 0, 0]],\n",
    "    name = \"image pyramid\",\n",
    ")\n",
    "print(ome_zarr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e13ce",
   "metadata": {},
   "source": [
    "Now we add a new storage location (\"store\") for the pyramidal file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_zarr_path = tiff_image_path.parent / \"pyramidal_chunked_image\"\n",
    "ome_store = zarr.DirectoryStore(ome_zarr_path)\n",
    "ome_group = ome_zarr_image.to_zarr(ome_store, path='', overwrite=True)\n",
    "print(ome_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221c541",
   "metadata": {},
   "source": [
    "The code to access the array is quite complicated - we need to fill it with values again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28d22c-fe9c-430c-a653-4c3387814a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ome_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "level0_array = ome_group[ome_zarr_image.attributes.multiscales[0].datasets[0].path]\n",
    "tiff_dask.to_zarr(level0_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4dca4",
   "metadata": {},
   "source": [
    "Now let's create more levels by downsampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a56124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "full_res_spec = ArraySpec.from_array(zarr_array)\n",
    "print(\"Original array specification: \", full_res_spec)\n",
    "\n",
    "downsample_levels = [0, 1, 2]\n",
    "downsampled_specs = [\n",
    "    full_res_spec.model_copy(\n",
    "        update={\"shape\": tuple(math.ceil(i / 2**d) for i in full_res_spec.shape)\n",
    "    }) for d in downsample_levels\n",
    "]\n",
    "print(\"Downsampled array specifications: \", downsampled_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_zarr_image = Image.new(\n",
    "    array_specs = downsampled_specs,\n",
    "    paths = [f\"level{d}\" for d in downsample_levels],\n",
    "    axes = [\n",
    "        Axis(name=\"x\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"y\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"z\", type=\"space\", unit=\"um\")\n",
    "    ],\n",
    "    global_scale = [voxel_size, voxel_size, voxel_size],\n",
    "    scales = [[2**d, 2**d, 2**d] for d in downsample_levels],\n",
    "    translations = [[0, 0, 0] for d in downsample_levels],\n",
    "    name = \"mouse tibia\"\n",
    ")\n",
    "print(ome_zarr_image)\n",
    "\n",
    "ome_group = ome_zarr_image.to_zarr(ome_store, path='', overwrite=True)\n",
    "print(ome_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we need to downsample efficiently with dask, so we don't load everything into memory\n",
    "# for d in downsample_levels:\n",
    "#     level_d_array = ome_group[ome_zarr_image.attributes.multiscales[0].datasets[d].path]\n",
    "#     level_d_array[:] = zarr_array[::2**d, ::2**d, ::2**d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc581a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari\n",
    "\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.open(ome_zarr_path, plugin=\"napari-ome-zarr\")\n",
    "# napari.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
